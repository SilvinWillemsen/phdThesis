\chapter{Physical Modelling of Musical Instruments}\label{ch:physMod}
At the time of writing, an uncountable number of digital musical instruments exist. From digital keyboards that create sounds from a various real (and non-real) instruments to digital instrument plug-ins that music producers use in their Digital Audio Workstations (DAWs) to create their music. Until recently, many of these digital instruments were based on samples, or recordings of their real-life counterparts. As computing power increased over the last few decades, using \textit{physical models} rather than samples gained more and more popularity in these applications.

Physical modelling, in the context of sound and music, is a way to generate sound based on physical processes. This includes string vibrations in a guitar, air propagation in a trumpet, or even the sound reflections in a concert hall! This work focuses on simulating\footnote{The term \textit{emulated} is only used in the title of this work (because of the alliteration), but is synonymous to \textit{simulated} in this context.} traditional musical instruments using physical modelling. 
The interest in physically modelling traditional musical instruments is twofold: sound generation, and understanding of the underlying physical processes. The former is the main focus of this PhD project. One of the reasons why one would use physical models rather than recordings (or samples) of the real instrument, is that it is more flexible to player control. Consider the violin as an example. The performer controls bow force, velocity and position along the string, as well as the finger determining the pitch of the string. A physical model can generate the sound on the spot based on these performance parameters. If samples were to be used, every single combination of these parameters would need to be recorded in order to capture the entire instrument.
A more in-depth reasoning behind using physical models for sound generation will be given in Section \ref{sec:why}.

This chapter continues by giving a brief overview of the history of physical modelling for sound synthesis.

\section{A Brief History}\label{sec:history}

Digital sound synthesis gained an increased interest in the last few decades. In the 1960s, efficient sinusoidal-based sound synthesis techniques such as additive synthesis [\SWcomment[stefania?]], or FM (frequency modulation) synthesis \cite{Chowning1973} were invented, the latter of which became widely popular through the Yamaha DX7 synthesiser created in 1983 that synthesised sounds based solely on this technique \cite{DX7}. Through a simple change of variables the same formula could generate sounds ranging from brass instruments to drums. 
 
As computing power increased, so did the popularity of using physics-based simulations of musical instruments. Most likely the very first example of a physically modelled sound is the ``Bicycle Built for Two'' by Kelly, Lochbaum, and Matthews in 1961\footnote{\url{http://ccrma.stanford.edu/~jos/wav/daisy-klm.wav}}. It uses what later got known as the Kelly-Lochbaum vocal-tract model to generate a voice and was published the year thereafter \cite{Kelly1962}. 

The very first musical instrument simulations based on differential equations, more specifically the wave equation, were carried out around 1970 by Hiller and Ruiz \cite{Ruiz1969, Hiller1971I, Hiller1971II}. The sound generation, however, was far from real-time and it took several minutes to generate only $1$ second of sound. In 1983, Cadoz et al. introduced CORDIS, a real-time sound generating system based on mass-spring networks \cite{Cadoz1983}.
The first physical model of the bowed string was due to McIntyre et al. in their 1983 publication \cite{McIntyre1983}. In the same year Karplus and Strong devised an extremely efficient way to generate a string sound in \cite{Karplus1983} later known as the Karplus-Strong algorithm. Based on these ideas, Smith coined the term \textit{digital waveguides} around 1990 \cite{Smith1987, Smith1992} and continued to develop the method \cite{Smith2010b}.
Around the same time, Adrien in \cite{Adrien1991} and later Morrison and Adrien in \cite{Morrison1993} introduced \textit{modal synthesis}, a way to generate an object's sound by decomposing it into its modes of vibration. 

Although more techniques have been developed in the last 20-30 years, most of the developments in the field of physical modelling for musical instruments are based on those presented in this section. Before moving on to further details about these methods in Section \ref{sec:physModTech}, a modular approach to subdivide a musical instrument will be presented.

\section{Exciter-Resonator Approach}
\SWcomment[honestly not so sure where to put this section. I want to talk about the fact that all the physical modelling techniques mentioned]
Nearly any musical instrument can be subdivided into a resonator component and an exciter component, both of which can be simulated, as well as the interaction between them. This modular approach to musical instruments was first introduced by Borin, De Poli and Sarti in \cite{Borin1989} and is used to structure this work \todo{interactions in Borin1989 are not the same as the interactions "Part" here..}. Examples or resonator-exciter combinations are the violin and the bow, or the trumpet and the lips of the player. %\SWcomment[Note that Part \ref{part:interactions} does not include the interactions between the resonator and exciter, but rather the interactions between different parts of the resonator itself, for example, the interactions between the string and the body of a violin, which both are resonators.]
A resonator is a passive system, in this work mostly assumed to be linear, and does not emit sound unless triggered by an external source. Exciters can be seen as these external sources, and generally have a nonlinear element.\footnote{A quick explanation of (non)linear systems: The behaviour of linear systems does not change with the level of the input. Instead, it only scales (linearly) with the input level: an input to a linear system with twice the amplitude yields an output of twice the amplitude. The behaviour of nonlinear systems, however, does change depending on the level of the input. Although linear systems are rarely found in the real world, under low amplitude excitations they can still be considered linear and their nonlinear effects can be ignored.} Exciters insert energy into a resonator and cause it to vibrate and emit sound. In the real world, the interaction between the exciter and the resonator is bi-directional, hence called an interaction. In other words, the exciter not only affects the state of the resonator, but the resonator affects the exciter as well. For the most part, this is also what is attempted to model in this work.

The next section will talk about various techniques that can be used to implement the resonator.

\section{Physical Modelling Techniques}\label{sec:physModTech}
The time-evolution of dynamic systems, including that of musical instruments, can be well described by partial differential equations (PDEs) \cite{Fletcher1998, theBible}. Examples of a dynamic systems are a guitar string, a drum-membrane, or air propagation in a concert hall; three very different concepts, but all based on the same types of equations of motion. Many of these equations and other knowledge currently available on the physics of musical instruments have been collected by Fletcher and Rossing in \cite{Fletcher1998}. Though these equations are very powerful, only few have a closed-form solution, and in order for them to be implemented, they need to be approximated. In the past decades, much research has been done on implementing these PDEs to model and simulate different musical instruments. Great overviews of implementation techniques are given by, for example, Vesa V{\"a}lim{\"a}ki et al. in \cite{Valimaki2006} and Julius O. Smith in \cite{Smith2010a, Smith2010b}. 
\\

The most popular physical modelling techniques, also mentioned in Section \ref{sec:history} that are described in this literature can be found below:
\\
\\
\textit{Modal Synthesis} decomposes a system into a series of uncoupled `modes of vibration' and can be seen as a physically-based additive synthesis technique. First used in a musical context by Morrison and Adrien in \cite{Morrison1993}, it is a technique that is still used today due to its computational efficiency, especially when simulating higher-dimensional systems such as (two-dimensional) plates or (three-dimensional) rooms. It is especially effective when used to describe a linear system with a small number of long-resonating modes \cite{Bilbao2018, Smith2010a}. When used to describe nonlinear systems, however, the modes become `coupledâ€™ and the system will quickly become more computationally expensive. Recent developments using the FAUST programming language allow a 3D-mesh model of any three-dimensional object to directly be decomposed into its modes of vibration and used as a sound-generating physical model \cite{MichonMesh2Faust2017}.
\\
\\
\textit{Finite-Difference Time Domain} methods (FDTD) aim to solve PDEs by approximating them with difference equations, discretising a continuous system into grid-points in space and time. In a musical context, this technique was first used for the case of string vibration by Hiller and Ruiz in \cite{Ruiz1969, Hiller1971I, Hiller1971II} and later by Chaigne in \cite{Chaigne1992, Chaigne1994}. Bilbao extensively describes this method in \cite{theBible, Bilbao2018}. Although computationally expensive, especially when working with higher-dimensional systems, this technique can accurately model any system, whether it is linear or nonlinear, time-invariant or time-variant.
\\
\\
\textit{Digital Waveguide Modelling} (or Digital Waveguides (DWGs)) is a modelling technique that discretises wave propagation and scattering. The technique was first presented by Smith in \cite{Smith1992}, and is mostly used for one-dimensional systems, such as strings and acoustic tubes and decomposes their system into travelling wave components. This technique has also been used in higher-dimensional systems, but is superior in efficiency when used in the one-dimensional case \cite{Valimaki2006}. Some authors have combined DWGs with FD schemes (such as in \cite{Erkut2002, Maestre2014}) to accurately model nonlinear behaviour while maintaining high-speed implementation.
\\
\\
\textit{Mass-spring networks} can be similar in nature to FDTD methods, but treat each grid point as an individual mass connected to other masses through springs in a network. Pioneered in a musical context by Cadoz in \cite{Cadoz1979, Cadoz1983, Cadoz1993} it is currently being further developed by Leonard and Villeneuve in a real-time, interactive environment \cite{Villeneuve2019, Leonard2019}.

Although other techniques have been developed over the years, including Functional Transformation Method \cite{Trautmann2003} or modelling in the wave domain \cite{Fettweis1986}, most work in the field of physical modelling for sound synthesis is based on these fundamental techniques.

\subsubsection{Discussion}
This work focuses on physical modelling using FDTD methods. The main advantage of these methods is that they are extremely general and flexible in terms of the types and amount of systems they can model. They allow any set of PDEs to be directly numerically simulated without making any assumptions regarding travelling wave solutions or modes. DWGs, for example, assume a travelling wave solution, which makes dispersive effects, let alone nonlinear effects, extremely hard to model using this technique. To use modal synthesis to model a PDE, it requires the system to have closed-form or analytical solution. If this is not available, (finite-element) analysis of the system could be performed to obtain the modal shapes and frequencies of the system. This in itself is very computationally expensive and requires a lot of storage if the modal data needs to be saved. 
\todo{check all of this} 
\SWcomment[Moreover, FDTD methods allow for various PDEs, fx. a violin body and four strings, to be connected in a fairly straightforward manner.] 

The main drawback of FDTD methods is the fact that working with these methods requires great attention to numerical stability of the solution \cite{theBible}. For a wrong choice of parameters, the implemented system could become unstable and ``explode''\footnote{I learned the hard way that one should always implement a limiter when working with real-time physical models.}. Stability analysis as well as energy analysis techniques are invaluable in the process of ensuring a stable implementation and much attention to this will be given throughout this work.

A final drawback of using FDTD methods is that -- especially for higher-dimensional systems -- they require much more computationally heavy than other methods, such as DWGs or modal synthesis techniques. The bright side, if one believes in Moore's law \cite{Moore1965}, is that it can be assumed that computing power will continue to increase and that within several years, running high-quality simulations of musical instruments based on FDTD methods in real time, would not be an issue. More information on real-time implementation is given below. 



\section{Why? Applications of Physical Modelling}\label{sec:why}
So why would we go through all this hassle of modelling musical instruments? Could we not use a recording of the original and play that back at the right moment? Or taking another step back, why not buy a real instrument and learn to play that instead? 

\subsection{Samples vs. Physical Modelling}
Digital musical instruments based on recordings of an actual instrument, referred to as \textit{samples}, have an advantage of having an optimally realistic sound. As the output of the digitised instrument is exactly that of the original instrument, the digital version should sound indistinguishable from the original. Furthermore, using samples is extremely computationally efficient as it simply requires loading the data and playing this back to the player.

That said, these are the only advantages of using samples over physical models for digitising a musical instrument. Samples are static and unable to adapt to changes in performance; the recording is made by one player, using a specific microphone and location. Moreover, capturing the the entire interaction space of an instrument is nearly impossible. Imagine recording a violin with every single combination of bowing force, velocity, position, duration and other aspects such as vibrato, pizzicato. Even if a complete sample library could be created, this would contain an immense amount of data. Using physical models to simulate the musical instrument, on the other hand, allows the sound to be generated on the spot based on physical parameters that the user can interact with. The 

Trade off between storage and speed, or hard-disk and processing power.


\subsection{Resurrect Old or Rare Instruments}
Why not use the real instrument in the first place? 
In some cases, recording samples of an instrument is not even possible as they are too old, too rare or too vulnerable to be played. The physics of the instrument, including the geometry and material properties, are available, and could potentially be modelled digitally. 


Even popular instruments require maintenance and might need to be replaced after years of usage. 

Entire orchestras come from plug-ins\todo{FULL DOC SWEEP: plugins or plug-ins}


\subsection{Go beyond what is physically possible} 
As a virtual \todo{check wording} instrument is not restricted to the laws of physics in the real world, this opens up a world of possibilities.

Musical instrument simulations make it possible for parameters like shape, size, material properties, etc. to be dynamically changed, which is physically impossible or very hard to do. Furthermore, different instrument components can be combined to create hybrid instruments. For example, one could bow the air in a trumpet, or lip-excite a string (similar to what Smith states in \cite{Smith2010a}). This could potentially resulting in unique sounds that can only be created using physical models.


\SWcomment[``I'm a musician. Will I be out of a job if you keep making physical models?'' Physical modelling is not here to replace the original instruments and the musicians playing them. Instead, it can be used as a tool to understand the physics of existing instruments and possibly go beyond. Simulated instruments are not restricted by physics anymore and could provide new ways of expression for the musician.]


\section{Real-Time Implementation}
Although many techniques to digitally simulate musical instruments exist, samples are still mainly used 

proving that we have only recently reached the computing power in personal computers to make real-time playability of these models an option. The biggest challenge in real-time audio applications as opposed to those only involving graphics, is that the sample rate is extremely high. As Nyquist's sampling theory tells us, a sampling rate of at least 40 kHz is necessary to produce frequencies up to the human hearing limit of 20 kHz \textbf{[Nyquist]}. Visuals 

Even though physical modelling has been a popular research field in the past few decades, relatively little research has been done on making the models work in real-time, i.e., `playableâ€™ \cite{Mehes2016}. Several virtual string instruments and different electric pianos have been made real-time by Pfeifle and Bader in \cite{Pfeifle2012, Pfeifle2015, Pfeifle2017}. They used field programmable gate arrays (FPGAs) for implementing models based on FDTD methods. Furthermore, Rolandâ€™s V-series use COSM (Composite Object Sound Modelling) technology \cite{Bybee2019} that implement real-time physical models in hardware instruments. In the NESS project \cite{Bilbao2019CMJa,Bilbao2019CMJb}, Stefan Bilbao and his team focused on implementing systems using FDTD methods in real-time.

Real-time: no noticeable latency


\section{Project Objectives and Main Contributions}
Over the past few decades, much work has been done on the accurate modelling of physical phenomena. In the field of sound and musical instruments.. 

From \cite{Fletcher1998} to \cite{Bilbao2019CMJb}



The main objective of this thesis is to implement existing physical models simulated using FDTD methods in real time. Many of the physical models and methods presented in this thesis are taken from the literature and are thus not novel. 

Secondly, to combine the existing physical models to get complete instruments and be able to control them in real time.

As FDTD methods are quite rigid, changing parameters on the fly, i.e., while the instrument simulation is running, is a challenge.  Other techniques, such as modal synthesis, are much more suitable for this, but come with the drawbacks mentioned in Section \ref{sec:physModTech}. Therefore, a novel method was devised to smoothly change parameters over time, introducing this to FDTD methods. \todo{Put this work into perspective of the literature (higher level)}

\section{Thesis Outline}
The dissertation is divided into several parts which in their turn are divided in chapters. 

\textbf{Part \ref{part:introduction}: Introduction} introduced the field of physical modelling for musical instruments in this chapter by giving a brief history of the field and provides and background for the project. Furthermore, the project objectives and contributions to the field have been detailed. Chapter \ref{ch:FDTD} will provide a thorough introduction to finite-difference time-domain methods using simple sound-generating systems as examples, after which Chapter \ref{ch:analysis} will introduce several analysis techniques in a tutorial-like fashion. This part has -- as much as possible -- been written in layman's terms and perhaps more pedagogical than could be expected of a dissertation. 

\textbf{Part \ref{part:resonators}: Resonators} introduces various physical models in isolation that have been used extensively throughout the project. 

\textbf{Part \ref{part:exciters}: Exciters} shows two different ways that the resonators introduced in Part \ref{part:resonators} can be excited. 

\textbf{Part \ref{part:interactions}: Interactions} shows two different ways that the resonators can interact with each other: 


Introduction to finite-difference methods and analysis techniques

Less focus on continuous equations and mathematical substantiation, but more on the practical and implementation side of things.

Despite the ``collection of papers'' format that I chose to use for this work, the style of  

Models used over the course of the project divided into resonators in part \ref{part:resonators}, exciters in part \ref{part:exciters} and the interactions between them in \ref{part:interactions}.

Focus on real-time implementation and control of the models in part \ref{part:realtime}