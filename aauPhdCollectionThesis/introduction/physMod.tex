\chapter{Physical Modelling of Musical Instruments}\label{ch:physMod}

Digital sound synthesis an increased interest in the last few decades. In the 1960s, efficient sinusoidal-based sound synthesis techniques such as additive synthesis \cite{additive}, or FM (frequency modulation) synthesis \cite{Chowning1973} were invented. The latter became widely popular through the Yamaha DX7 synthesiser created in 1983 that synthesised sounds based solely on this technique \cite{DX7}. Through a simple change of variables the same formula could generate sounds ranging from brass instruments to drums. 
 
As computing power increased, so did the popularity of using physics-based simulations of musical instruments. Most likely the very first example of a physically modelled sound example is the ``Bicycle Built for Two'' by Kelly, Lochbaum, and Matthews in 1961\footnote{\href{http://ccrma.stanford.edu/~jos/wav/daisy-klm.wav}{http://ccrma.stanford.edu/~jos/wav/daisy-klm.wav}}. It uses what later got known as the Kelly-Lochbaum vocal-tract model to generate a voice and was published the year thereafter \cite{Kelly1962}. 

to more to more computationally demanding techniques in the 

The simulation\footnote{The term \textit{emulated} is only used in the title of this work (because of the alliteration), but is synonymous to \textit{simulated} in this context.} of traditional musical instruments has seen. From 

\SWcomment[Stefania, I need you here for the proper references :)]

The interest in creating virtual or digital musical instruments 

Virtualisation or digitisation 

A simulation of a musical instrument is defined as an implementation of 

where the sound is generated on the spot. Sample-based sound synthesis, where the sound of a real instrument has been recorded and is played back through a digital device is not considered a simulation.

The umbrella term would be digital musical instrument,  


\section{Exciter-Resonator Approach}
Nearly any musical instrument can be subdivided into a resonator component, an exciter component, and the interaction between them. This modular approach to musical instruments was first introduced by Borin, De Poli and Sarti in \cite{Borin1989} and is used to structure this work \todo{interactions in Borin1989 are not the same as the interactions "Part" here..}. Examples or resonator-exciter combinations are the violin and the bow, or the trumpet and the lips of the player. Note that Part \ref{part:interactions} does not include the interactions between the resonator and exciter, but rather the interactions between different parts of the resonator itself, for example, the interactions between the string and the body of a violin, which both are resonators. \todo{reread} 

A resonator is a passive system, in this work mostly assumed to be linear, that does not emit sound unless triggered by an external source. Exciters can be seen as these external sources, and generally have a nonlinear element. Exciters insert energy into a resonator and cause it to vibrate and emit sound.

In the real world, the interaction between the exciter and the resonator is bi-directional, hence called an interaction. In other words, the exciter not only affects the state of the resonator, but the resonator affects the exciter as well. For the most part, this is also what is attempted to model in this work.


\section{Physical Modelling Techniques}\label{sec:physModTech}
The time-evolution of dynamic systems, including that of musical instruments, can be well described by partial differential equations (PDEs) \cite{Fletcher1998, theBible}. Examples of a dynamic systems are a guitar string, a drum-membrane, or air propagation in a concert hall; three very different concepts, but all based on the same types of equations of motion. Many of these equations and other knowledge currently available on the physics of musical instruments have been collected by Fletcher and Rossing in \cite{Fletcher1998}. Though these equations are very powerful, only few have a closed-form solution, and in order for them to be implemented, they need to be approximated. In the past decades, much research has been done on implementing these PDEs to model and simulate different musical instruments. Great overviews of implementation techniques are given by, for example, Vesa V{\"a}lim{\"a}ki et al. in \cite{Valimaki2006} and Julius O. Smith in \cite{Smith2010a, Smith2010b}. 
\\

The most popular physical modelling techniques that are described in this literature can be found below:
\\
\\
\textit{Modal Synthesis} decomposes a system into a series of uncoupled `modes of vibration' and can be seen as a physically-based additive synthesis technique. First used in a musical context by Morrison and Adrien in \cite{Morrison1993}, it is a technique that is still used today due to its computational efficiency, especially when simulating higher dimensional systems such as (two-dimensional) plates or (three-dimensional) rooms. It is especially effective when used to describe a linear system with a small number of long-resonating modes \cite{Bilbao2018, Smith2010a}. When used to describe nonlinear systems, however, the modes become `coupled’ and the system will quickly become more computationally expensive. Recent developments using the FAUST programming language allow a 3D-mesh model of any three-dimensional object to directly be decomposed into its modes of vibration \cite{MichonMesh2Faust2017}.
\\
\\
\textit{Finite-Difference Time Domain} methods (FDTD) aim to solve PDEs by approximating them with difference equations, discretising a continuous system into grid-points in space and time. In a musical context, this technique was first used for the case of string vibration in \cite{Ruiz1969, Hiller1971I, Hiller1971II} and later in \cite{Chaigne1992, Chaigne1994}. Stefan Bilbao extensively describes this method in \cite{theBible, Bilbao2018}. Although computationally expensive, especially when working with higher-dimensional systems, this technique can accurately model any system, whether it is linear or nonlinear, time-invariant or time-variant.
\\
\\
\textit{Digital Waveguide Modelling} (or Digital Waveguides (DWGs)) is a modelling technique that discretises wave propagation and scattering. The technique was first presented in \cite{Smith1992}, and is mostly used for one-dimensional systems, such as strings and acoustic tubes and decomposes their system into travelling wave components. This technique has also been used in higher-dimensional systems, but is superior in efficiency when used in the one-dimensional case \cite{Valimaki2006}. Some authors have combined DWGs with FD schemes (such as in \cite{Erkut2002, Maestre2014}) to accurately model nonlinear behaviour while maintaining high-speed implementation.
\\
\\
\textit{Mass-spring networks} can be similar in nature to FDTD methods, but treat each grid point as an individual mass connected to other masses through springs in a network. Pioneered in a musical context by Cadoz in \cite{Cadoz1979, Cadoz1983, Cadoz1993} it is currently being further developed by Leonard and Villeneuve in a real-time, interactive environment \cite{Villeneuve2019, Leonard2019}.

Other techniques include Functional Transformation Method \cite{Trautmann2003}, state-space modelling \cite{Matignon1992}, \SWcomment[wave-domain modelling  and energy-based port-Hamiltonian] \todo{should I include this}


This work focuses on physical modelling using FDTD methods. The main advantage of these methods is that they are extremely general and flexible in terms of the types and amount of systems they can model. They allow any set of PDEs can be directly numerically simulated without making any assumptions regarding travelling wave solutions or modes. DWGs, for example, assume a travelling wave solution, which makes dispersive effects, let alone nonlinear effects, extremely hard to model using this technique. To use modal synthesis to model a PDE, it requires the system to have closed-form or analytical solution. If this is not available, (finite-element) analysis of the system could be performed to obtain the modal shapes and frequencies of the system. This in itself is very computationally expensive and requires a lot of storage if the modal data needs to be saved. 
\todo{check all of this} 

Moreover, FDTD methods allow for various PDEs, fx. a violin body and four strings, to be connected in a fairly straightforward manner. 


The main drawback of FDTD methods is the fact that working with these methods requires great attention to numerical stability of the solution. For a wrong choice of parameters, the implemented system could become unstable and ``explode''\footnote{I learned the hard way that one should always implement a limiter when working with real-time physical modelling using FDTD methods.}. Stability analysis as well as energy analysis techniques are invaluable in the process of ensuring a stable implementation and much attention to this will be given throughout this work.

A final drawback of using FDTD methods is that -- especially for higher-dimensional systems -- they require much more computationally heavy than other methods, such as DWGs or modal synthesis techniques. The bright side, if one believes in Moore's law \cite{Moore1965}, is that it can be assumed that computing power will continue to increase and that within several years, running high-quality simulations of musical instruments based on FDTD methods in real time, would not be an issue. More information on real-time implementation is given below. 

\section{Real-Time Implementation}
Although many techniques to digitally simulate musical instruments exist

proving that we have only recently reached the computing power in personal computers to make real-time playability of these models an option. The biggest challenge in real-time audio applications as opposed to those only involving graphics, is that the sample rate is extremely high. As Nyquist's sampling theory tells us, a sampling rate of at least 40 kHz is necessary to produce frequencies up to the human hearing limit of 20 kHz \textbf{[Nyquist]}. Visuals 

Even though physical modelling has been a popular research field in the past few decades, relatively little research has been done on making the models work in real-time, i.e., `playable’ \cite{Mehes2016}. Several virtual string instruments and different electric pianos have been made real-time by Pfeifle and Bader in \cite{Pfeifle2012, Pfeifle2015, Pfeifle2017}. They used field programmable gate arrays (FPGAs) for implementing models based on FDTD methods. Furthermore, Roland’s V-series use COSM (Composite Object Sound Modelling) technology \cite{Bybee2019} that implement real-time physical models in hardware instruments. In the NESS project \cite{Bilbao2019CMJa,Bilbao2019CMJb}, Stefan Bilbao and his team focused on implementing systems using FDTD methods in real-time.

Real-time: no noticeable latency

\section{Why?}\todo{exactly as in \cite{theBible}}
So why would we go through all this hassle of modelling musical instruments? Could we not use a recording of the original and play that back at the right moment? Or taking another step back, why not buy a real instrument and learn to play that instead? ``I'm a musician. Will I be out of a job if you keep making physical models?''


Physical modelling is not here to replace the original instruments and the musicians playing them. Instead, it can be used as a tool to understand the physics of existing instruments and possibly go beyond. Simulated instruments are not restricted by physics anymore and could provide new ways of expression for the musician. 

\subsection{Samples vs. Physical Modelling}
Digital musical instruments based on recordings of an actual instrument, referred to as \textit{samples}, have an advantage of having an optimally realistic sound. As the output of the digitised instrument is exactly that of the original instrument, the digital version should sound indistinguishable from the original. Furthermore, using samples is extremely computationally efficient as it simply requires loading the data and playing this back to the player.

That said, these are the only advantages of using samples over physical models for digitising a musical instrument. Samples are static and unable to adapt to changes in performance; the recording is made by one player, using a specific microphone and location. Moreover, capturing the the entire interaction space of an instrument is nearly impossible. Imagine recording a violin with every single combination of bowing force, velocity, position, duration and other aspects such as vibrato, pizzicato. Even if a complete sample library could be created, this would contain an immense amount of data. Using physical models to simulate the musical instrument, on the other hand, allows the sound to be generated on the spot based on physical parameters that the user can interact with. The 

Trade off between storage and speed, or hard-disk and processing power.


\subsection{Resurrect Old or Rare Instruments}
Why not use the real instrument in the first place? 
In some cases, recording samples of an instrument is not even possible as they are too old, too rare or too vulnerable to be played. The physics of the instrument, including the geometry and material properties, are available, and could potentially be modelled digitally. 


Even popular instruments require maintenance and might need to be replaced after years of usage. 

Entire orchestras come from plug-ins\todo{FULL DOC SWEEP: plugins or plug-ins}


\subsection{Go beyond what is physically possible} 
As a virtual \todo{check wording} instrument is not restricted to the laws of physics in the real world, this opens up a world of possibilities.

Musical instrument simulations make it possible for parameters like shape, size, material properties, etc. to be dynamically changed, which is physically impossible or very hard to do. Furthermore, different instrument components can be combined to create hybrid instruments. For example, one could bow the air in a trumpet, or lip-excite a string (similar to what Smith states in \cite{Smith2010a}). This could potentially resulting in unique sounds that can only be created using physical models.

\section{Project Objectives and Main Contributions}
Over the past few decades, much work has been done on the accurate modelling of physical phenomena. In the field of sound and musical instruments.. 

From \cite{Fletcher1998} to \cite{Bilbao2019CMJb}



The main objective of this thesis is to implement existing physical models simulated using FDTD methods in real time. Many of the physical models and methods presented in this thesis are taken from the literature and are thus not novel. 

Secondly, to combine the existing physical models to get complete instruments and be able to control them in real time.

As FDTD methods are quite rigid, changing parameters on the fly, i.e., while the instrument simulation is running, is a challenge.  Other techniques, such as modal synthesis, are much more suitable for this, but come with the drawbacks mentioned in Section \ref{sec:physModTech}. Therefore, a novel method was devised to smoothly change parameters over time, introducing this to FDTD methods. \todo{Put this work into perspective of the literature (higher level)}

\section{Thesis Outline}
The dissertation is divided into several parts which in their turn are divided in chapters. 

\textbf{Part \ref{part:introduction}: Introduction} introduced the field of physical modelling for musical instruments in this chapter by giving a brief history of the field and provides and background for the project. Furthermore, the project objectives and contributions to the field have been detailed. Chapter \ref{ch:FDTD} will provide a thorough introduction to finite-difference time-domain methods using simple sound-generating systems as examples, after which Chapter \ref{ch:analysis} will introduce several analysis techniques in a tutorial-like fashion. This part has -- as much as possible -- been written in layman's terms and perhaps more pedagogical than could be expected of a dissertation. 

\textbf{Part \ref{part:resonators}: Resonators} introduces various physical models in isolation that have been used extensively throughout the project. 

\textbf{Part \ref{part:exciters}: Exciters} shows two different ways that the resonators introduced in Part \ref{part:resonators} can be excited. 

\textbf{Part \ref{part:interactions}: Interactions} shows two different ways that the resonators can interact with each other: 


Introduction to finite-difference methods and analysis techniques

Less focus on continuous equations and mathematical substantiation, but more on the practical and implementation side of things.

Despite the ``collection of papers'' format that I chose to use for this work, the style of  




Models used over the course of the project divided into resonators in part \ref{part:resonators}, exciters in part \ref{part:exciters} and the interactions between them in \ref{part:interactions}.

Focus on real-time implementation and control of the models in part \ref{part:realtime}